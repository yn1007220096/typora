# 项目介绍



# 业务场景

# 线上问题

1.大促全链路压测，方法tp999 冲到200s 。

![image-20220513113529803](/Users/yunan10/Desktop/150/md/项目.assets/image-20220513113529803.png)

# 压测

积分商城 QPS 也就一两百， 青绿QPS 可能得几千或者更多，看代码 怎么提升，加缓存。

问题？ 一般多少QPS 就不能查库了，辉哥：不一定，可能得看数据库的性能。 问题？怎么设计数据库能让性能好一点？

## 618大促压测流程

1.初压：看机器能不能扛住去年双11的量

2.黄金流程每次上线特别慢，即使只改一行代码，也要全链路压测

3.猴子捣乱，偷偷停掉你数据库，延迟网络，下掉机器，看你的流量，tp99,tp999,可用率是否受影响

4.限流：预估各种流量，不能过高流量把自己系统干挂

5.如果自己系统被别人依赖，评估对别人影响。

6.每个机器其实性能并不一样，摘调性能不好的机器

## 方法性能

### 衡量指标

#### 1.满足三高：

高并发：看QPS

高性能：tp99 tp999

高可用：可用率

#### 2.TP90 TP99 TP999

TP90:满足90%的网络请求所需要的最低耗时(90%的请求耗时情况)。

TP99:满足99%的网络请求所需要的最低耗时。TP99=10ms，标识这段时间99%的请求都在10毫秒以内。

TP999:满足99.9%的网络请求所需要的最低耗时。

MAX: 某段时间内耗时最大的，比如MAX=1000ms，表示这段时间最耗时的一次请求是1s，MAX高表示偶有一次请求，耗时很大。



TP指标：

TP=Top Percentile，指一个时间段内，统计该方法每次调用所消耗的时间，并将这些时间按从小到大的顺序进行排序, 并取出结果为 ： 总次数 * 指标数 = 对应TP指标的值， 再取出排序好的对应位置时间。

TP50、TP90、TP99、TP999 计算方式一致。TP90，TP99，TP999对方法性能要求很高，接口性能参数"999线"就是TP999。



计算方式：

进位取整（请求总次数*x%），取该请求值中最低耗时，注：x为TPx中的x

TP50 = (int)(TOTAL_RUNS * 0.50);
 TP90 = (int)(TOTAL_RUNS * 0.90);
 TP99 = (int)(TOTAL_RUNS * 0.99);
 TP99_9 = (int)(TOTAL_RUNS * 0.999);
 TP100 = (int)(TOTAL_RUNS * 1);

比如：有四次请求耗时分别为：

10ms，1000ms，100ms，2ms

排序：[2ms,10ms,100ms,1000ms]

TP50：4次请求中，50%的请求数为4*0.50，进位取整也就是2次，满足这全部2次请求的最低耗时为10ms，也就是TP50=10ms

TP99：4次请求中，99%的请求数为4*0.99，进位取整也就是4次，满足这全部4次请求的最低耗时为1000ms，也就是TP99的=1000ms

#### 3.如何提升方法性能？

1.属性转换 可能影响接口性能 bean.copyproperties  影响性能，底层用的反射  (属性用多少 set多少)

2.单机房单个接口 最大QPS能有多少？ （其实取决于接口的性能）

#### 4.京东例子

2022-01-13全链路汇天压测-京豆概况：

1）京豆余额接口：QPS峰值为267483；CPU峰值为95.07%；TP99 3ms；21年双11倍数0.54；

2）购物返利等接口没有压测流量。

 

压测明细：

| 一、详细数据 |              |                      |                |                             |         |        |              |      |       |
| ------------ | ------------ | -------------------- | -------------- | --------------------------- | ------- | ------ | ------------ | ---- | ----- |
| 系统         | 接口         | 0120汇天压测（秒级） |                |                             |         |        |              |      |       |
|              |              | docker核数           | 压测docker核数 | Docker分钟级qps峰值时cpu(%) | MAX CPU | QPS    | 21年双11倍数 | TP99 | TP999 |
| 京豆对外服务 | 京豆对外余额 | 2240                 | 786            | 92.04%                      | 95.07%  | 267483 | 0.54         | 3ms  | 12ms  |
|              | 京豆过期接口 |                      |                |                             |         |        | 0.00         |      |       |
|              | 近七天过期   |                      |                |                             |         | 120511 | 12.05        | 4ms  | 12ms  |
|              | 用户京豆明细 |                      |                |                             |         | 121366 | -            | 9ms  | 18ms  |
| 京豆台账     | 京豆台账余额 | 1880                 | 880            | 53.08%                      | 95.21%  | 267970 | 0.54         | 0ms  | 2ms   |
|              | 近七天过期   |                      |                |                             |         | 119557 | 11.96        | 4ms  | 9ms   |
|              | 用户京豆明细 |                      |                |                             |         | 119557 | 2.39         | 10ms | 13ms  |
| 购物返利     | 购物返利     | 736                  | 368            | 1.24%                       | 21.49%  | 5835   | 0.02         | 2ms  | 4ms   |

![image-20220512103542304](/Users/yunan10/Desktop/150/md/项目.assets/image-20220512103542304.png)

 ### 怎么配报警

如果对外接口正常10qps，高峰 30 qps，大促60 qps，压测能能扛住100qps。要配两种日志

warn40-50  不看也没事，提醒自己

严重    70-80电话报警 容易压垮接口

### 方法优化

1.场景：全链路压测的时候，从pfinder（可以看全流程调用链路，针对于分布式，微服务链路太长）发现对外服务花了 70msm,  调rpc接口20ms. 我们接口只是负责转调为什么会花费50m s?

解决：经排查，用了属性转换 bean.copyproperties  影响性能，底层用的反射，后来改成了属性用多少 set多少

# jsf

配超时时间，配限流

# 数据库

连接超时时间？

# 编码习惯

## 1.接口读写分离

## 2.日志

1.一定要打日志，线上出问题，快速定位问题是第一要务。虽然加日志会影响性能，可以堆机器啊。

动态更改日志级别

### 什么时候打

1.rpc 一定写 （调你的入参， 出参 都得打出来）

## 3.报警

报警一定要合理：控制在10条以内   对外服务 tp99 tp999。不然太多，也不会看，失去报警的意义。